version: '3.8'

services:
  # --- Embeddings Server ---
  vllm-embed:
    image: vllm/vllm-openai:latest
    container_name: vllm-embed
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes:
      - '${MODELS_PATH}:/root/.cache/huggingface'
    ports:
      - "8000:8000"
    ipc: host
    command: --model ${EMBEDDINGS_MODEL} --task embed  --gpu-memory-utilization 0.5 --host 0.0.0.0 --port 8000
    restart: unless-stopped
  # --- LLM Server ---
  vllm-llm:
    image: vllm/vllm-openai:latest
    container_name: vllm-llm
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes:
      - '${MODELS_PATH}:/root/.cache/huggingface'
    ports:
      - "8001:8000"
    ipc: host
    command: --model ${LLM_MODEL} --gpu-memory-utilization 0.5  --max-model-len 16384 --enable-auto-tool-choice  --tool-call-parser hermes --host 0.0.0.0 --port 8000
    restart: unless-stopped

  # --- Agent Server ---
  agent:
    image: executeit/langgraph-a2a-server:latest
    container_name: agent
    ports:
      - "8008:8000"
    volumes:
      - agent_storage:/qdrant/storage
    # environment:
    #   - LLM_BASE_URL=${LLM_MODEL}
    #   - LLM_MODEL=${}
    #   - LLM_API_KEY=${}
    #   - EMBEDDINGS_BASE_URL=${}
    #   - EMBEDDINGS_MODEL=${}
    #   - EMBEDDINGS_API_KEY=${}
    #   - QDRANT_API=${}
    #   - QDRANT_API_KEY=${}
    #   - S3_BUCKET=${}
    #   - S3_ENDPOINT=${}
    #   - S3_AKID=${}
    #   - S3_SK=${}
    #   - LANGFUSE_SECRET_KEY=${}
    #   - LANGFUSE_PUBLIC_KEY=${}
    #   - LANGFUSE_BASE_URL=${}
    #   - ATLASSIAN_MCP_URL=${}
    restart: unless-stopped

  # --- Local Vector DB (QDRANT) ---
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333" # Port API HTTP
      - "6334:6334" # Port gRPC
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__API_KEY=${QDRANT_API_KEY}
    restart: unless-stopped

  # --- Local S3 (MINIO) ---
  minio:
    image: minio/minio:latest
    container_name: local_s3
    ports:
      - "9000:9000" # API S3 (dla Twojego skryptu Python: S3_ENDPOINT)
      - "9001:9001" # Konsola administratora (przeglÄ…darka)
    environment:
      MINIO_ROOT_USER: ${AWS_ACCESS_KEY_ID} # Odpowiednik: AWS_ACCESS_KEY_ID / S3_AKID
      MINIO_ROOT_PASSWORD: ${AWS_SECRET_ACCESS_KEY} # Odpowiednik: AWS_SECRET_ACCESS_KEY / S3_SK
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    restart: unless-stopped

  # --- Atlassian MCP Server ---
  atlassian-mcp:
    image: ghcr.io/sooperset/mcp-atlassian:latest
    container_name: atlassian-mcp
    ports:
      - "9002:9000"
    environment:
      # - JIRA_URL=${JIRA_URL}
      # - JIRA_USERNAME=${JIRA_USERNAME}
      # - JIRA_API_TOKEN=${JIRA_API_TOKEN}
      - CONFLUENCE_URL=${CONFLUENCE_URL}
      - CONFLUENCE_USERNAME=${CONFLUENCE_USERNAME}
      - CONFLUENCE_API_TOKEN=${CONFLUENCE_API_TOKEN}
    command: --transport streamable-http --port 9000 -vv
    restart: unless-stopped
volumes:
  qdrant_storage:
  minio_data:
  huggingface_cache:
  agent_storage:
